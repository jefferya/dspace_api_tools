"""
##############################################################################################
# desc: bitstream_access_control_test.py:
#     Test the HTML UI DSpace Item views to test the associated DSpace Bitstreams access control permissions
# license: CC0 1.0 Universal (CC0 1.0) Public Domain Dedication
# date: March 26, 2025
##############################################################################################
"""

import argparse
import csv
import logging

from urllib.parse import urljoin

from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait

# from selenium.webdriver.support import expected_conditions as EC
from selenium.common.exceptions import NoSuchElementException
from selenium.common.exceptions import TimeoutException


from utils import utilities as utils


def parse_args():
    """
    Parse command line arguments
    """

    parser = argparse.ArgumentParser()

    parser.add_argument(
        "--input",
        required=True,
        help="Location of a CSV generated by compare_csv with a column 'id_field'.",
    )
    parser.add_argument(
        "--output",
        required=True,
        help="Location to store CSV output.",
    )
    parser.add_argument(
        "--id_field",
        required=True,
        help="The ID field in the CSV to use as a DSpace URL.",
        default="dspace_id",
    )
    parser.add_argument(
        "--root_url",
        required=True,
        help="The root URL to the DSpace server [http://localhost:4000].",
        default="http://localhost:4000",
    )
    parser.add_argument(
        "--timeout",
        required=False,
        help="The timeout to test for bitstreams (sec).",
        default="5",
    )
    parser.add_argument(
        "--logging_level", required=False, help="Logging level.", default="INFO"
    )

    return parser.parse_args()


#
def get_url(root_url, item_id):
    """
    Given an ID, get the associated response page
    """
    return urljoin(root_url, f"items/{item_id}/full")


def populate_result(identifier="", bitstream_url="", access="", note=""):
    """
    Build the dict for populating the CSV output
    Inspect the following:
        * access_restriction column: if blank, no access restriction
        * bitstream_url: if contains "request-a-copy" in the URL then there is an access restriction
        * note: if not empty then there was a failure to load the page or the URL contains no bitstreams
    """
    return {
        "item_id": f"{identifier}",
        "bitstream_url": f"{bitstream_url}",
        "access_restriction": f"{access}",
        "note": f"{note}",
    }


def check_for_bitstreams(wait):
    """
    After trying to access the DSpace Item as an anonymous user the expected result is
    a dynamically generated HTML page with a list of bitstreams
    """
    # Check that the Download links are present
    # element = wait.until(EC.presence_of_element_located((By.XPATH, "//ds-file-download-link")))
    return wait.until(
        lambda web_driver: web_driver.find_elements(
            By.XPATH, "//ds-file-download-link[descendant::a/@href]"
        )
    )


def process_bitstreams(bitstreams, csv_writer, id_field, row):
    """
    Process each bitstream and add details to the CSV output
    """

    for bitstream_element in bitstreams:
        # logging.info("Download element rendered [%s]", bitstream_element.text)
        # logging.info("Download element rendered [%s]", dir(bitstream_element))
        logging.debug(
            "Download element rendered [%s]",
            bitstream_element.get_attribute("outerHTML"),
        )
        span_list = bitstream_element.find_elements(By.XPATH, "a/span[@aria-label]")
        access = span_list[0].get_attribute("aria-label") if span_list else ""
        a_list = bitstream_element.find_elements(By.XPATH, "a[@href]")
        bitstream_url = a_list[0].get_attribute("href") if a_list else ""

        logging.info(
            "     %s: [%s] access restrictions[%s] url[%s]",
            id_field,
            row[id_field],
            access,
            bitstream_url,
        )

        csv_writer.writerow(populate_result(row[id_field], bitstream_url, access))


def check_for_login_prompt(web_driver):
    """
    When trying to access a DSpace Item with password protection at the metadata/bitstream level
    the dynamic HTML redirects to a login screen
    """
    return web_driver.find_elements(By.XPATH, "//input[@data-test='password']")


#
def process(csv_reader, csv_writer, web_driver, args):
    """
    Process CSV rows and call DSpace delete
    """

    for row in csv_reader:
        logging.info("Item id: %s", row[args.id_field])

        url = get_url(args.root_url, row[args.id_field])
        web_driver.get(url)

        logging.debug(web_driver.page_source)

        try:
            # Wait until dynamic page rendering completed
            wait = WebDriverWait(web_driver, args.timeout)

            # Test if there are bitsreams on the page
            bitstreams = check_for_bitstreams(wait)

            # Process bitstreams and add check results to the CSV
            process_bitstreams(bitstreams, csv_writer, args.id_field, row)

            logging.debug(web_driver.page_source)
        except NoSuchElementException as e:
            logging.info(
                " Element does not exist: id[%s] [%s]",
                row[args.id_field],
                e.__class__.__name__,
            )
            csv_writer.writerow(
                populate_result(row[args.id_field], note=f"{e.__class__.__name__}")
            )
        except TimeoutException as e:
            # Two causes: page unavailable or no files to download on the page (e.g., a password protected item)
            # add logic to handle the two cases (note: complicated by dynamically generated HTML)
            check_login = check_for_login_prompt(web_driver)
            note = (
                "Password required to view item"
                if check_login
                else e.__class__.__name__
            )
            logging.info("  Timeout: id[%s] [%s]", row[args.id_field], note)
            csv_writer.writerow(populate_result(row[args.id_field], note=note))


#
def main():
    """
    Main entry point
    """

    args = parse_args()

    utils.configure_logging(args.logging_level)

    web_options = Options()
    web_options.add_argument("--headless")
    web_options.add_argument("--disable-gpu")
    web_options.add_argument("--window-size=1920,1080")
    web_options.add_argument("--no-sandbox")
    web_options.add_argument("--disable-extensions")
    web_options.add_experimental_option(
        "prefs", {"profile.managed_default_content_settings.images": 2}
    )
    web_options.timeout = {"script": 30000}
    web_driver = webdriver.Chrome(options=web_options)

    output_header = populate_result().keys()

    with open(args.input, "r", encoding="utf-8", newline="") as input_file:
        csv_reader = csv.DictReader(input_file)
        with open(args.output, "w", encoding="utf-8", newline="") as output_file:
            csv_writer = csv.DictWriter(output_file, fieldnames=output_header)
            csv_writer.writeheader()
            process(csv_reader, csv_writer, web_driver, args)

    web_driver.quit()


#
if __name__ == "__main__":
    main()
