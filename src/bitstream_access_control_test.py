"""
##############################################################################################
# desc: bitstream_access_control_test.py:
#     Test the HTML UI DSpace Item views to test the associated DSpace Bitstreams access control permissions
# license: CC0 1.0 Universal (CC0 1.0) Public Domain Dedication
# date: March 26, 2025
##############################################################################################
"""

import argparse
import csv
import logging

from urllib.parse import urljoin
from bs4 import BeautifulSoup

import requests

from utils import utilities as utils


def parse_args():
    """
    Parse command line arguments
    """

    parser = argparse.ArgumentParser()

    parser.add_argument(
        "--input",
        required=True,
        help="Location of a CSV generated by compare_csv with a column 'id_field'.",
    )
    parser.add_argument(
        "--id_field",
        required=True,
        help="The ID field in the CSV to use as a DSpace URL.",
        default="dspace_id",
    )
    parser.add_argument(
        "--root_url",
        required=True,
        help="The root URL to the DSpace server [http://localhost:4000].",
        default="http://localhost:4000",
    )
    parser.add_argument(
        "--logging_level", required=False, help="Logging level.", default="INFO"
    )

    return parser.parse_args()


#
def get_url(root_url, item_id):
    """
    Given an ID, get the associated response page
    """
    url = urljoin(root_url, f"items/{item_id}/full")
    return requests.get(url, timeout=10)


def check_response(response):
    """
    check the bitstream download access controls
    """
    ret = None
    if response.status_code == 200:
        # Lookup attached file in the DSpace HTML
        logging.info("URL [%s] code [%s]", response.url, response.status_code)
        bs = BeautifulSoup(response.text, "html.parser")
        elements = bs.find_all("ds-file-download-link")
        if elements:
            logging.info("URL [%s] has download element", response.url)
            for element in elements:
                span = element.find("span")
                if "aria-label" in span:
                    logging.info("URL [%s] %s", response.url, span["aria-label"])
                else:
                    logging.error("URL [%s] aria-label not found", response.url)
        else:
            logging.info("URL [%s] has no download element", response.url)

    else:
        logging.error(
            "Error with url [%s] code [%s] %s",
            response.url,
            response.status_code,
            response.text,
        )
    return ret


#
def process(csv_reader, id_field, root_url):
    """
    Process CSV rows and call DSpace delete
    """
    for row in csv_reader:
        logging.info(row[id_field])
        response = get_url(root_url, row[id_field])
        logging.info(response)
        results = check_response(response)
        print(results)


#
def main():
    """
    Main entry point
    """

    args = parse_args()

    utils.configure_logging(args.logging_level)

    with open(args.input, "r", encoding="utf-8", newline="") as input_file:
        csv_reader = csv.DictReader(
            input_file,
        )
        process(csv_reader, args.id_field, args.root_url)


#
if __name__ == "__main__":
    main()
